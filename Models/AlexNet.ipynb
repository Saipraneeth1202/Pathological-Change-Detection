{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfV-7GaOhNla"
      },
      "source": [
        "# **AlexNet** #\n",
        "\n",
        "In this project I will be creating a Neural network model similar to AlexNet.<br>\n",
        "\n",
        "**About Dataset** : <br>\n",
        "Here I am taking X-ray dataset which has 5144 training images and 1288 test images. The number of categories are 3. \n",
        "\n",
        "The image dimension is 224x224x3 i.e. It is a  colour image.<br>\n",
        "The classes are  : [covid,normal,pneumonia]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qzfA3NWdgY4D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#imports\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, jaccard_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Loading and Transformations ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data directories\n",
        "train_data_dir = r\"D:\\8th_semester\\DL\\DL_Project\\Preprocessed_Data\\Preprocessed_Data\\train\"\n",
        "test_data_dir = r\"D:\\8th_semester\\DL\\DL_Project\\Preprocessed_Data\\Preprocessed_Data\\test\"\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "num_classes = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data augmentation and normalization for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Normalization for testing\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5144 images belonging to 3 classes.\n",
            "Found 1288 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "# Load and augment training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Augmentation and Normalization for Training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Normalization for Testing\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1vMpvHsmnje"
      },
      "source": [
        "### **Model Creation** ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ezXHcDscmqy6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 96)      2688      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 96)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 111, 111, 256)     614656    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 55, 55, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 55, 55, 384)       885120    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 55, 55, 384)       1327488   \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 55, 55, 256)       884992    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 27, 27, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 186624)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              764416000 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 12291     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 784924547 (-1155269108.00 Byte)\n",
            "Trainable params: 784924547 (-1155269108.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\layer_utils.py:146: RuntimeWarning: overflow encountered in scalar multiply\n",
            "  total_memory_size += weight_shape * per_param_size\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(96, (3, 3), strides=(1, 1), activation='relu', input_shape=(224, 224, 3), padding='same'),\n",
        "    MaxPooling2D((3, 3), strides=(2, 2)),\n",
        "    Conv2D(256, (5, 5), padding='same', activation='relu'),\n",
        "    MaxPooling2D((3, 3), strides=(2, 2)),\n",
        "    Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
        "    Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
        "    Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
        "    MaxPooling2D((3, 3), strides=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(4096, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(4096, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')  # Use `num_classes` to match your output layer\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Training ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEeCwzLDqHUj",
        "outputId": "fdf7aa69-e711-45c7-b0ea-cdc670d1d7d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:From C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node Adam/Square_10 defined at (most recent call last):\n  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n\n  File \"c:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n\n  File \"c:\\Program Files\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 542, in dispatch_queue\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 531, in process_one\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 775, in execute_request\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Local\\Temp\\ipykernel_13804\\2699845585.py\", line 3, in <module>\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1154, in train_step\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 544, in minimize\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1223, in apply_gradients\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 652, in apply_gradients\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1253, in _internal_apply_gradients\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1342, in apply_grad_to_update_var\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 241, in _update_step\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\adam.py\", line 199, in update_step\n\nOOM when allocating tensor with shape[186624,4096] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node Adam/Square_10}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2238]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Model training\u001b[39;00m\n\u001b[0;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node Adam/Square_10 defined at (most recent call last):\n  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n\n  File \"c:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n\n  File \"c:\\Program Files\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 542, in dispatch_queue\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 531, in process_one\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 775, in execute_request\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Local\\Temp\\ipykernel_13804\\2699845585.py\", line 3, in <module>\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 1154, in train_step\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 544, in minimize\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1223, in apply_gradients\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 652, in apply_gradients\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1253, in _internal_apply_gradients\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1342, in apply_grad_to_update_var\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 241, in _update_step\n\n  File \"C:\\Users\\MEDHA TRUST\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\adam.py\", line 199, in update_step\n\nOOM when allocating tensor with shape[186624,4096] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node Adam/Square_10}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2238]"
          ]
        }
      ],
      "source": [
        "# Model training\n",
        "epochs = 20\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Training Visualization ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtT0waKFqgQc"
      },
      "outputs": [],
      "source": [
        "# Retrieve a list of training and validation losses and accuracies\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "# Number of epochs\n",
        "epochs_range = range(1, epochs + 1)\n",
        "\n",
        "# Create the plots for training and validation loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(epochs_range, train_loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Create the plots for training and validation accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(epochs_range, train_accuracy, 'r', label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_accuracy, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"D:\\8th_semester\\DL\\DL_Project\\models\\AlexNet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "load the saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_alexnet = load_model(\"D:\\8th_semester\\DL\\DL_Project\\models\\AlexNet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predict ,Test and Evaluate ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the Model\n",
        "test_loss, test_accuracy = loaded_alexnet.evaluate(test_generator)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Predict\n",
        "y_true = test_generator.classes\n",
        "y_pred = loaded_alexnet.predict(test_generator)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "print(\"Predicted Classes = \" ,y_pred_classes)\n",
        "\n",
        "\n",
        "#Evaluate the Model\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=list(test_generator.class_indices.keys())))\n",
        "\n",
        "# Generate a confusion matrix\n",
        "confusion_mat = confusion_matrix(y_true, y_pred_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Calculate precision, recall, and F1-score for each class\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred_classes)\n",
        "\n",
        "print(\"Precision for each class:\", precision)\n",
        "print(\"Recall for each class:\", recall)\n",
        "print(\"F1-Score for each class:\", f1_score)\n",
        "\n",
        "# Calculate Jaccard Score for each class\n",
        "jaccard_scores = jaccard_score(y_true, y_pred_classes, average=None)\n",
        "print(\"Jaccard Score for each class:\", jaccard_scores)\n",
        "\n",
        "# Calculate Type 1 error and Type 2 error for each class\n",
        "# Type 1 error (False Positives) - how many times a class was predicted but shouldn't have been\n",
        "type_1_errors = confusion_mat.sum(axis=0) - np.diag(confusion_mat)  # Column-wise sum minus the diagonal\n",
        "\n",
        "# Type 2 error (False Negatives) - how many times a class wasn't predicted but should have been\n",
        "type_2_errors = confusion_mat.sum(axis=1) - np.diag(confusion_mat)  # Row-wise sum minus the diagonal\n",
        "\n",
        "print(\"Type 1 Errors for each class:\", type_1_errors)\n",
        "print(\"Type 2 Errors for each class:\", type_2_errors)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
